{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c8eb35",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ef344",
   "metadata": {},
   "source": [
    "### Will a patient have a 10 year risk of developing a cardio vascular diseases?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f178b0f",
   "metadata": {},
   "source": [
    "Table of contents\n",
    "\n",
    "1. Introduction\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature Selection\n",
    "4. Feature Scaling\n",
    "5. Test - Train Split\n",
    "6. Resampling\n",
    "7. Model Pipeline\n",
    "8. Modelling & Evaluation\n",
    "9. Apply model\n",
    "\n",
    "## Introduction \n",
    "\n",
    "\n",
    "### Problem: \n",
    "The World Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant/risk factors of heart disease as well as predict the overall risk using logistic regression Data Preparation\n",
    "\n",
    "Source: The dataset is publically available on the Kaggle website, and it is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD).The dataset provides the patients’ information. It includes over 4,000 records and 15 attributes. Variables Each attribute is a potential risk factor. There are both demographic, behavioral and medical risk factors.\n",
    "\n",
    "## Attributes:\n",
    "\n",
    "### Demographic:\n",
    "Sex: male or female(Nominal)\n",
    "\n",
    "Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
    "\n",
    "Education: no further information provided\n",
    "\n",
    "### Behavioral:\n",
    "\n",
    "Current Smoker: whether or not the patient is a current smoker (Nominal)\n",
    "\n",
    "Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
    "\n",
    "### Information on medical history:\n",
    "BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n",
    "\n",
    "Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n",
    "\n",
    "Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n",
    "\n",
    "Diabetes: whether or not the patient had diabetes (Nominal)\n",
    "\n",
    "### Information on current medical condition:\n",
    "Tot Chol: total cholesterol level (Continuous)\n",
    "\n",
    "Sys BP: systolic blood pressure (Continuous)\n",
    "\n",
    "Dia BP: diastolic blood pressure (Continuous)\n",
    "\n",
    "BMI: Body Mass Index (Continuous)\n",
    "\n",
    "Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
    "\n",
    "Glucose: glucose level (Continuous)\n",
    "\n",
    "### Target variable to predict:\n",
    "10 year risk of coronary heart disease (CHD) - (binary: “1”, means “Yes”, “0” means “No”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba61484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries and magic functions\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74289d3",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ddf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Admin\\OneDrive\\Documents\\data science\\Machine learning\\Framingham\\framingham.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d807b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for dupicates\n",
    "duplicate_df = df[df.duplicated()]\n",
    "duplicate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019816b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values\n",
    "df.isna().sum()\n",
    "null = df[df.isna().any(axis=1)]\n",
    "null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is already loaded and cleaned from previous steps\n",
    "\n",
    "# Checking distributions using histograms\n",
    "fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(15, 20))  # Adjust the number of rows and columns as needed\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(df.columns):\n",
    "        df[df.columns[i]].hist(ax=ax, bins=20)\n",
    "        ax.set_title(df.columns[i])\n",
    "    else:\n",
    "        fig.delaxes(ax)  # Remove unused axes\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which features are correlated with each other and are correlated with the outcome variable\n",
    "df_corr = df.corr()\n",
    "sns.heatmap(df_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a6630",
   "metadata": {},
   "source": [
    "### Conclusions from Heatmap:\n",
    "\n",
    "We are dropping the column education because a doctor would have to decide on which education level to put a patient and this could result in very subjective outcomes and it is also not very handy to put in practice.\n",
    "\n",
    "The two features are not correlated to the outcome variable. In that case we would have kept them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns education and glucose\n",
    "df = df.drop(['education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for more missing data \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb26240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all rows with missing data\n",
    "df = df.dropna()\n",
    "df.isna().sum()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1cb97",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c165b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the features with the most importance for the outcome variable Heart Disease\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# separate independent & dependent variables\n",
    "X = df.iloc[:,0:14]  #independent columns\n",
    "y = df.iloc[:,-1]    #target column i.e price range\n",
    "\n",
    "# apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(11,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75968d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureScores = featureScores.sort_values(by='Score', ascending=False)\n",
    "featureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397cad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing feature selection\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.barplot(x='Specs', y='Score', data=featureScores, palette = \"GnBu_d\")\n",
    "plt.box(False)\n",
    "plt.title('Feature importance', fontsize=16)\n",
    "plt.xlabel('\\n Features', fontsize=14)\n",
    "plt.ylabel('Importance \\n', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ddde6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the 10 most impactful features for the target variable\n",
    "features_list = featureScores[\"Specs\"].tolist()[:10]\n",
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210a4670",
   "metadata": {},
   "source": [
    "We will only keep those features that have the strongest relationship with the output variable. These features are:\n",
    "\n",
    "Systolic Blood Pressure\n",
    "\n",
    "Glucose\n",
    "\n",
    "Age\n",
    "\n",
    "Cholesterin\n",
    "\n",
    "Cigarettes per Day\n",
    "\n",
    "Diastolic Blood Pressure\n",
    "\n",
    "Hypertensive\n",
    "\n",
    "Diabetes\n",
    "\n",
    "Blood Pressure Medication\n",
    "\n",
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with selected features\n",
    "\n",
    "df = df[['sysBP', 'glucose','age','totChol','cigsPerDay','diaBP','prevalentHyp','diabetes','BPMeds','male','TenYearCHD']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation again\n",
    "df_corr = df.corr()\n",
    "sns.heatmap(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ad8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers\n",
    "df.describe()\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed629ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zooming into cholesterol outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['totChol'])\n",
    "plt.title('Boxplot of Total Cholesterol')\n",
    "plt.show()\n",
    "\n",
    "# Identifying outliers in the 'totChol' column\n",
    "outliers = df[df['totChol'] > 500]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5135436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 2 outliers in cholesterin\n",
    "df = df.drop(df[df.totChol > 599].index)\n",
    "\n",
    "# Plotting the boxplot for 'totChol' after dropping outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['totChol'])\n",
    "plt.title('Boxplot of Total Cholesterol after Dropping Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42590b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e417a9c",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29fc9a6",
   "metadata": {},
   "source": [
    "Since we want to try out different models, and also these that use distance as a measure, we will scale our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "\n",
    "#assign scaler to column:\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_clean), columns=df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.describe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a882cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clarify what is y and what is x label\n",
    "y = df_scaled['TenYearCHD']\n",
    "X = df_scaled.drop(['TenYearCHD'], axis = 1)\n",
    "\n",
    "# divide train test: 80 % - 20 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ac54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b383b",
   "metadata": {},
   "source": [
    "### Resampling imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking balance of outcome variable\n",
    "target_count = df_scaled.TenYearCHD.value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "\n",
    "# Plotting the count of the outcome variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=df_scaled.TenYearCHD, palette=\"OrRd\")\n",
    "plt.box(False)\n",
    "plt.xlabel('Heart Disease No/Yes', fontsize=11)\n",
    "plt.ylabel('Patient Count', fontsize=11)\n",
    "plt.title('Count Outcome Heart Disease\\n')\n",
    "plt.savefig('Balance_Heart_Disease.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b52e8e0",
   "metadata": {},
   "source": [
    "We can see that the proportion is 5.57:1 which is not well balanced. One of the major issues when dealing with unbalanced datasets relates to the metrics used to evaluate a model. Using simpler metrics like accuracy_score can be misleading. In a dataset with highly unbalanced classes, if the classifier always \"predicts\" the most common class without performing any analysis of the features, it will still have a high accuracy rate, obviously illusory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a5a82",
   "metadata": {},
   "source": [
    "### UNDERSAMPLING METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d65024",
   "metadata": {},
   "source": [
    "Undersampling aims to decrease the number of instances from the overrepresented class in the data set. In our case, these techniques will decrease the number of fraudulent transactions in our data to approximately 50:50. If we do not balance the number of instances, most classification algorithms will heavily focus on the majority class. As a result, it might seem like your algorithm is achieving superb results when, in reality, it is simply always predicting the majority class.\n",
    "\n",
    "The easiest way to do so is to randomly select observations from the majority class and remove them from the data set until we achieve a balance between the majority and minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataframe\n",
    "shuffled_df = df_scaled.sample(frac=1, random_state=4)\n",
    "\n",
    "# Put all the CHD class in a separate dataset\n",
    "CHD_df = shuffled_df.loc[shuffled_df['TenYearCHD'] == 1]\n",
    "\n",
    "# Randomly select 611 observations from the non-CHD (majority class)\n",
    "non_CHD_df = shuffled_df.loc[shuffled_df['TenYearCHD'] == 0].sample(n=611, random_state=42)\n",
    "\n",
    "# Concatenate both dataframes again\n",
    "normalized_df = pd.concat([CHD_df, non_CHD_df])\n",
    "\n",
    "# Check new class counts\n",
    "print(normalized_df.TenYearCHD.value_counts())\n",
    "\n",
    "# Plot new count\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=normalized_df.TenYearCHD, palette=\"OrRd\")\n",
    "plt.box(False)\n",
    "plt.xlabel('Heart Disease No/Yes', fontsize=11)\n",
    "plt.ylabel('Patient Count', fontsize=11)\n",
    "plt.title('Count Outcome Heart Disease after Resampling\\n')\n",
    "#plt.savefig('Balance_Heart_Disease.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27343d8c",
   "metadata": {},
   "source": [
    "### Model Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "# We have normalized_df, X_test, and y_test\n",
    "\n",
    "# Splitting data (assuming X_train and y_train are defined correctly)\n",
    "# y_train = normalized_df['TenYearCHD']\n",
    "# X_train = normalized_df.drop('TenYearCHD', axis=1)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [LogisticRegression(), SVC(), DecisionTreeClassifier(), KNeighborsClassifier(2)]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "    # Evaluate each classifier\n",
    "    for classifier in classifiers:\n",
    "        pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "        pipe.fit(X_train, y_train)   \n",
    "        accuracy = pipe.score(X_test, y_test) * 100\n",
    "        print(f\"The accuracy score of {classifier.__class__.__name__} is: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52806bf",
   "metadata": {},
   "source": [
    "#### Modelling & Evaluation (without Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b5ce9b",
   "metadata": {},
   "source": [
    "1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression again with the balanced dataset\n",
    "\n",
    "normalized_df_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "normalized_df_reg_pred = normalized_df_reg.predict(X_test)\n",
    "\n",
    "# check accuracy: Accuracy: Overall, how often is the classifier correct? Accuracy = (True Pos + True Negative)/total\n",
    "acc = accuracy_score(y_test, normalized_df_reg_pred)\n",
    "print(f\"The accuracy score for LogReg is: {round(acc,3)*100}%\")\n",
    "\n",
    "# f1 score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "f1 = f1_score(y_test, normalized_df_reg_pred)\n",
    "print(f\"The f1 score for LogReg is: {round(f1,3)*100}%\")\n",
    "\n",
    "# Precision score: When it predicts yes, how often is it correct? Precision=True Positive/predicted yes\n",
    "precision = precision_score(y_test, normalized_df_reg_pred)\n",
    "print(f\"The precision score for LogReg is: {round(precision,3)*100}%\")\n",
    "\n",
    "# recall score: True Positive Rate(Sensitivity or Recall): When it’s actually yes, how often does it predict yes? True Positive Rate = True Positive/actual yes\n",
    "recall = recall_score(y_test, normalized_df_reg_pred)\n",
    "print(f\"The recall score for LogReg is: {round(recall,3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7064121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix LogReg\n",
    "\n",
    "cnf_matrix_log = confusion_matrix(y_test, normalized_df_reg_pred)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix_log), annot=True,cmap=\"Reds\" , fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix Logistic Regression\\n', y=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ed3e2",
   "metadata": {},
   "source": [
    "2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "#initialize model\n",
    "svm = SVC()\n",
    "\n",
    "#fit model\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "normalized_df_svm_pred = svm.predict(X_test)\n",
    "\n",
    "# check accuracy: Accuracy: Overall, how often is the classifier correct? Accuracy = (True Pos + True Negative)/total\n",
    "acc = accuracy_score(y_test, normalized_df_svm_pred)\n",
    "print(f\"The accuracy score for SVM is: {round(acc,3)*100}%\")\n",
    "\n",
    "# f1 score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "f1 = f1_score(y_test, normalized_df_svm_pred)\n",
    "print(f\"The f1 score for SVM is: {round(f1,3)*100}%\")\n",
    "\n",
    "# Precision score: When it predicts yes, how often is it correct? Precision=True Positive/predicted yes\n",
    "precision = precision_score(y_test, normalized_df_svm_pred)\n",
    "print(f\"The precision score for SVM is: {round(precision,3)*100}%\")\n",
    "\n",
    "# recall score: True Positive Rate(Sensitivity or Recall): When it’s actually yes, how often does it predict yes? True Positive Rate = True Positive/actual yes\n",
    "recall = recall_score(y_test, normalized_df_svm_pred)\n",
    "print(f\"The recall score for SVM is: {round(recall,3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8911de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix SVM\n",
    "\n",
    "cnf_matrix_svm = confusion_matrix(y_test, normalized_df_svm_pred)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix_svm), annot=True,cmap=\"Reds\" , fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix SVM\\n', y=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017db9ec",
   "metadata": {},
   "source": [
    "3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "#initialize model\n",
    "dtc_up = DecisionTreeClassifier()\n",
    "\n",
    "# fit model\n",
    "dtc_up.fit(X_train, y_train)\n",
    "\n",
    "normalized_df_dtc_pred = dtc_up.predict(X_test)\n",
    "\n",
    "# check accuracy: Accuracy: Overall, how often is the classifier correct? Accuracy = (True Pos + True Negative)/total\n",
    "acc = accuracy_score(y_test, normalized_df_dtc_pred)\n",
    "print(f\"The accuracy score for DTC is: {round(acc,3)*100}%\")\n",
    "\n",
    "# f1 score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "f1 = f1_score(y_test, normalized_df_dtc_pred)\n",
    "print(f\"The f1 score for DTC is: {round(f1,3)*100}%\")\n",
    "\n",
    "# Precision score: When it predicts yes, how often is it correct? Precision=True Positive/predicted yes\n",
    "precision = precision_score(y_test, normalized_df_dtc_pred)\n",
    "print(f\"The precision score for DTC is: {round(precision,3)*100}%\")\n",
    "\n",
    "# recall score: True Positive Rate(Sensitivity or Recall): When it’s actually yes, how often does it predict yes? True Positive Rate = True Positive/actual yes\n",
    "recall = recall_score(y_test, normalized_df_dtc_pred)\n",
    "print(f\"The recall score for DTC is: {round(recall,3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a456fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix Decision Tree\n",
    "\n",
    "cnf_matrix_dtc = confusion_matrix(y_test, normalized_df_dtc_pred)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix_dtc), annot=True,cmap=\"Reds\" , fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix Decision Tree\\n', y=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb6b39",
   "metadata": {},
   "source": [
    "4. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from scipy import stats\n",
    "\n",
    "# Initialize model\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# Fit model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "normalized_df_knn_pred = knn.predict(X_test)\n",
    "\n",
    "# Check accuracy\n",
    "acc = accuracy_score(y_test, normalized_df_knn_pred)\n",
    "print(f\"The accuracy score for KNN is: {round(acc * 100, 3)}%\")\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, normalized_df_knn_pred)\n",
    "print(f\"The F1 score for KNN is: {round(f1 * 100, 3)}%\")\n",
    "\n",
    "# Precision score\n",
    "precision = precision_score(y_test, normalized_df_knn_pred)\n",
    "print(f\"The precision score for KNN is: {round(precision * 100, 3)}%\")\n",
    "\n",
    "# Recall score\n",
    "recall = recall_score(y_test, normalized_df_knn_pred)\n",
    "print(f\"The recall score for KNN is: {round(recall * 100, 3)}%\")\n",
    "\n",
    "# Suppress the FutureWarning from SciPy by setting `keepdims` parameter\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    # Code that triggers the warning\n",
    "    mode, _ = stats.mode([1, 2, 3], keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74562cc",
   "metadata": {},
   "source": [
    "Result: The KNN model has the highest accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Suppress specific FutureWarning from scipy.stats.mode\n",
    "warnings.filterwarnings(\"ignore\", message=\".*keepdims.*\", category=FutureWarning)\n",
    "\n",
    "# Assuming X_train, y_train, X_test, and y_test are properly defined\n",
    "\n",
    "# Train the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Check overfit of the KNN model\n",
    "# accuracy test and train\n",
    "acc_test = knn.score(X_test, y_test)\n",
    "print(\"The accuracy score of the test data is: \", acc_test * 100, \"%\")\n",
    "\n",
    "acc_train = knn.score(X_train, y_train)\n",
    "print(\"The accuracy score of the training data is: \", round(acc_train * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bae4d0",
   "metadata": {},
   "source": [
    "###### The scores for test and training data for the KNN model are similar. Therefore we do not expect the model to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c73860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross validation\n",
    "'''Cross Validation is used to assess the predictive performance of the models and and to judge \n",
    "how they perform outside the sample to a new data set'''\n",
    "\n",
    "cv_results = cross_val_score(knn, X, y, cv=5) \n",
    "\n",
    "print (\"Cross-validated scores:\", cv_results)\n",
    "print(\"The Accuracy of Model with Cross Validation is: {0:.2f}%\".format(cv_results.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a785e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix KNN\n",
    "\n",
    "cnf_matrix_knn = confusion_matrix(y_test, normalized_df_knn_pred)\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix_knn), annot=True,cmap=\"Reds\" , fmt='g')\n",
    "\n",
    "ax.set_xlabel('Predicted ');ax.set_ylabel('True'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da2bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AU ROC CURVE KNN\n",
    "'''the AUC ROC Curve is a measure of performance based on plotting the true positive and false positive rate \n",
    "and calculating the area under that curve.The closer the score to 1 the better the algorithm's ability to \n",
    "distinguish between the two outcome classes.'''\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, normalized_df_knn_pred)\n",
    "auc = roc_auc_score(y_test, normalized_df_knn_pred)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.box(False)\n",
    "plt.title ('ROC CURVE KNN')\n",
    "plt.show()\n",
    "\n",
    "print(f\"The score for the AUC ROC Curve is: {round(auc,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052d1f9",
   "metadata": {},
   "source": [
    "##### Applying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_questionnaire():\n",
    "    my_predictors = []\n",
    "    parameters=['sysBP', 'glucose','age','totChol','cigsPerDay','diaBP','prevalentHyp','diabetes','BPMeds','male']\n",
    "    \n",
    "    print('Input Patient Information:')\n",
    "    \n",
    "    age = input(\"Patient's age: >>> \") \n",
    "    my_predictors.append(age)\n",
    "    male = input(\"Patient's gender. male=1, female=0: >>> \") \n",
    "    my_predictors.append(male)\n",
    "    cigsPerDay = input(\"Patient's smoked cigarettes per day: >>> \") \n",
    "    my_predictors.append(cigsPerDay)\n",
    "    sysBP = input(\"Patient's systolic blood pressure: >>> \") \n",
    "    my_predictors.append(sysBP)\n",
    "    diaBP = input(\"Patient's diastolic blood pressure: >>> \")\n",
    "    my_predictors.append(diaBP)\n",
    "    totChol = input(\"Patient's cholesterin level: >>> \") \n",
    "    my_predictors.append(totChol)\n",
    "    prevalentHyp = input(\"Was Patient hypertensive? Yes=1, No=0 >>> \") \n",
    "    my_predictors.append(prevalentHyp)\n",
    "    diabetes = input(\"Did Patient have diabetes? Yes=1, No=0 >>> \") \n",
    "    my_predictors.append(diabetes)\n",
    "    glucose = input(\"What is the Patient's glucose level? >>> \") \n",
    "    my_predictors.append(diabetes)\n",
    "    BPMeds = input(\"Has Patient been on Blood Pressure Medication? Yes=1, No=0 >>> \")\n",
    "    my_predictors.append(BPMeds)\n",
    "    \n",
    "    my_data = dict(zip(parameters, my_predictors))\n",
    "    my_df = pd.DataFrame(my_data, index=[0])\n",
    "    scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "   \n",
    "    # assign scaler to column:\n",
    "    my_df_scaled = pd.DataFrame(scaler.fit_transform(my_df), columns=my_df.columns)\n",
    "    my_y_pred = knn.predict(my_df)\n",
    "    print('\\n')\n",
    "    print('Result:')\n",
    "    if my_y_pred == 1:\n",
    "        print(\"The patient will develop a Heart Disease.\")\n",
    "    if my_y_pred == 0:\n",
    "        print(\"The patient will not develop a Heart Disease.\")\n",
    "        \n",
    "start_questionnaire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9b1ba9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fhs_rf_model.pkl']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "joblib.dump(df, 'fhs_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c0424bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'fhs_rf_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "print(\"Model saved as 'fhs_rf_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48a6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
